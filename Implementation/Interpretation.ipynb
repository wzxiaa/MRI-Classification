{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator \n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold =4\n",
    "dataset = 'i'\n",
    "fold = str(fold)\n",
    "\n",
    "df_results_of_each_param = pd.read_pickle(\"./X\"+dataset+\"_results/results/fold\" + fold + \"/outerfold\" + fold + \"_results_for_each_param_setting.pkl\")\n",
    "df_results_of_each_fold = pd.read_pickle(\"./X\"+dataset+\"_results/results/fold\" + fold + \"/outerfold\" + fold + \"_results_for_each_fold.pkl\")\n",
    "good_results = pd.read_pickle(\"./X\"+dataset+\"_results/results/fold\" + fold + \"/outerfold\" + fold + \"_good_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_results.at[0,'precision_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_of_each_param.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_of_each_param.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes = df_results_of_each_param.at[0, \"test_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_of_each_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calculate how many instances of a particular subtype are correctly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCorrectlyClassifiedSubjects(y_pred, y_act, test_indexes, subtype, num_P, num_S):\n",
    "    \"\"\"Function to calculate the number of correctly classified instances.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        y_pred: numpy.array\n",
    "            Array of predicted results.\n",
    "        y_act: numpy.array\n",
    "            Array of actual results.\n",
    "        test_indexes: list\n",
    "            List of test indexes.\n",
    "        subtype: int\n",
    "            The subtype.\n",
    "        num_P: int\n",
    "            Number of Progressor subtypes.\n",
    "        num_S: int\n",
    "            Number of Stable subtypes.\n",
    "        weighting: int\n",
    "            Weighting value for classifier.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        count: int\n",
    "            Number of correctly classified instances.\n",
    "        index_of_intances_correctly_classified: list\n",
    "            Indexes of intances correctly classified.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "#     print(\"y_pred: \\n\", y_pred)\n",
    "#     print(\"y_act: \\n\", y_act)    \n",
    "#     print(\"test_indexes: \\n\", test_indexes)\n",
    "#     print((\"subtype: {}, num_P: {}, num_S: {}\").format(subtype, num_P, num_S))\n",
    "    n_class = num_P + num_S\n",
    "    \n",
    "    P_range, S_range = np.arange(0,num_P), np.arange(num_P, n_class)  \n",
    "#     print(\"P_range\", P_range)\n",
    "#     print(\"S_range\", S_range)\n",
    "    index_of_intances_correctly_classified = []\n",
    "    \n",
    "    if subtype in P_range:\n",
    "        for i in range(len(y_pred)):\n",
    "            # (1=stable, 2=progressor)\n",
    "            if y_pred[i] == subtype and y_act[i] == 2:\n",
    "                count += 1\n",
    "#                 print(i)\n",
    "                index_of_intances_correctly_classified.append(test_indexes[i])\n",
    "    \n",
    "    else:\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == subtype and y_act[i] == 1:\n",
    "                count += 1 \n",
    "#                 print(i)\n",
    "                index_of_intances_correctly_classified.append(test_indexes[i])\n",
    "                \n",
    "    return count, index_of_intances_correctly_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_c =pd.read_pickle(\"./Xs_results/results/fold0/arranged_good.pkl\")\n",
    "# print(test_c.iloc[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print('test_indexes')\n",
    "# indexes_t = test_c.iloc[8]['test_index']\n",
    "# # print(test_c.iloc[0]['test_index'])\n",
    "\n",
    "# # print('pred_y')\n",
    "# pred_y_t = test_c.iloc[8]['pred_y']\n",
    "# # print(test_c.iloc[0]['pred_y'])\n",
    "# # print('act_y')\n",
    "# act_y_t = test_c.iloc[8]['act_y']\n",
    "# # print(test_c.iloc[0]['act_y'])\n",
    "\n",
    "# results = calculateCorrectlyClassifiedSubjects(pred_y_t, act_y_t, indexes_t, 2, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate percentage of mutual features selected across all cross validation folds for a particular parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelectionValidation(df_results_of_each_fold, num_P, num_S, classifier, weighting, num_Features):\n",
    "    \"\"\"Function to unwrap the information of the feature selection for a particular\n",
    "        parameter setting result\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        df_results_of_each_fold: pandas.DataFrame\n",
    "            Dataframe that stores results for each fold.\n",
    "        num_P: int\n",
    "            Number of Progressor subtypes.\n",
    "        num_S: int\n",
    "            Number of Stable subtypes.\n",
    "        y_test: numpy.ndarray\n",
    "            The testing data labels.\n",
    "        classifiers: integer\n",
    "            A integer representing the classifiers used. \n",
    "            0: linear SVM\n",
    "            1: RandomForest\n",
    "            2: Logistic Regression\n",
    "        num_Features: int\n",
    "            Number of features to be selected during the feature selection step.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        percentage_mutual_features: float\n",
    "            Percentage of mutually selected features across all folds over specified number of features\n",
    "            to be selected\n",
    "        list_mf: list\n",
    "            List of the mutually selected features\n",
    "        num_mf: \n",
    "            Number of the mutually selected features\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_results_of_each_fold[\n",
    "                                        (df_results_of_each_fold['num_P'] == num_P) & \n",
    "                                        (df_results_of_each_fold['num_S'] == num_S) & \n",
    "                                        (df_results_of_each_fold['classifier'] == classifier) & \n",
    "                                        (df_results_of_each_fold['num_Features'] == num_Features) & \n",
    "                                        (df_results_of_each_fold['weighting'] == weighting)\n",
    "    ]['columns_selected']\n",
    "    features_selected = []\n",
    "#     print(df)\n",
    "    for row in df:\n",
    "        features_selected.append(row)\n",
    "#         print(features_selected)\n",
    "    mutual_features = set(features_selected[0]).intersection(*features_selected)\n",
    "#     print(len(mutual_features))\n",
    "    num_mf = len(mutual_features)\n",
    "    percentage_mutual_features = float(num_mf/num_Features)\n",
    "    list_mf = list(mutual_features)\n",
    "    return percentage_mutual_features, list_mf, num_mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate the frequencies of features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFeatureFrequencies(df_results_of_each_fold, num_P, num_S, classifier, num_Features, weighting):\n",
    "    \"\"\"Function to unwrap the information of the feature selection for a particular\n",
    "        parameter setting result\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        df_results_of_each_fold: pandas.DataFrame\n",
    "            Dataframe that stores results for each fold.\n",
    "        num_P: int\n",
    "            Number of Progressor subtypes.\n",
    "        num_S: int\n",
    "            Number of Stable subtypes.\n",
    "        y_test: numpy.ndarray\n",
    "            The testing data labels.\n",
    "        classifiers: integer\n",
    "            A integer representing the classifiers used. \n",
    "            0: linear SVM\n",
    "            1: RandomForest\n",
    "            2: Logistic Regression\n",
    "        num_Features: int\n",
    "            Number of features to be selected during the feature selection step.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        dic: dictionary\n",
    "            Dictionary containing all features selected as keys and corresponding frequencies as values.\n",
    "        features_list: list\n",
    "            List of the all features selected.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_results_of_each_fold[\n",
    "                                        (df_results_of_each_fold['num_P'] == num_P) & \n",
    "                                        (df_results_of_each_fold['num_S'] == num_S) & \n",
    "                                        (df_results_of_each_fold['num_Features'] == num_Features) &\n",
    "                                        (df_results_of_each_fold['classifier'] == classifier) &\n",
    "                                        (df_results_of_each_fold['weighting'] == weighting)\n",
    "                                        \n",
    "    ]['columns_selected']\n",
    "    features_selected = []\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    for row in df:\n",
    "        features_selected.append(row)\n",
    "        for i in row:\n",
    "            if i in dic:\n",
    "                dic[i] += 1\n",
    "            else:\n",
    "                dic[i] = 1\n",
    "                \n",
    "    # print(features_selected)\n",
    "    features_list = [j for sub in features_selected for j in sub]\n",
    "    # print(features_list)\n",
    "\n",
    "    return dic, features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def featuresThreshold(features_frequencies, features_selected_list, threshold):\n",
    "#     print(\"features_frequencies\", features_frequencies)\n",
    "#     print(\"features_selected_list\", features_selected_list)\n",
    "#     print(\"len features_frequencies\", len(features_frequencies))\n",
    "#     print(\"len features_selected_list\", len(features_selected_list))\n",
    "    \n",
    "    n_features = len(features_selected_list)\n",
    "    cut_off = math.ceil(n_features * threshold)\n",
    "#     print(cut_off)\n",
    "    \n",
    "    for index, feat in enumerate(features_selected_list[:cut_off]):\n",
    "        freq = features_frequencies[index]\n",
    "#         print((\"index : {}, feat: {}, freq: {}\").format(index, feat, features_frequencies[index]))\n",
    "        if freq < math.floor(threshold * 12):\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Plot histogram for frequencies of the features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFigures(df_results_of_each_param, feature_frequencies, PPV, num_c, num_P, num_S, classifier, num_Features, subtype, stability, weighting, indexes, analysis, path):\n",
    "    \"\"\"Function to plot the bar chart for frequencies of the features selected across all folds and the confusion\n",
    "        matrix and save them into one png file.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "        df_results_of_each_fold: pandas.DataFrame\n",
    "            Dataframe that stores results for each fold.\n",
    "        feature_frequencies: dictionary:\n",
    "            Dictionary containing all features as keys and the frequencies as values.\n",
    "        PPV: float\n",
    "            PPV value of the parameter setting.\n",
    "        num_c: int\n",
    "            Number of subjects correctly classified.\n",
    "        num_P: int\n",
    "            Number of Progressor subtypes.\n",
    "        num_S: int\n",
    "            Number of Stable subtypes.\n",
    "        classifiers: integer\n",
    "            A integer representing the classifiers used. \n",
    "            0: linear SVM\n",
    "            1: RandomForest\n",
    "            2: Logistic Regression\n",
    "        num_Features: int\n",
    "            Number of features to be selected during the feature selection step.\n",
    "        subtype: int\n",
    "            Subtype with highest PPV value.\n",
    "        stability: int\n",
    "            Stability of the parameter setting.\n",
    "        analysis: int\n",
    "            Analysis number.\n",
    "        path: string\n",
    "            Parent path to store the images.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot histogram\n",
    "    ######################################################################################\n",
    "\n",
    "    df = df_results_of_each_param[\n",
    "                                        (df_results_of_each_param['num_P'] == num_P) & \n",
    "                                        (df_results_of_each_param['num_S'] == num_S) & \n",
    "                                        (df_results_of_each_param['num_Features'] == num_Features) &\n",
    "                                        (df_results_of_each_param['classifier'] == classifier) &\n",
    "                                        (df_results_of_each_param['weighting'] == weighting)\n",
    "                                        \n",
    "    ]\n",
    "\n",
    "    test_index = df['test_index'].values.tolist()[0]\n",
    "    pred_y = df['pred_y'].values.tolist()[0]\n",
    "    act_y = df['act_y'].values.tolist()[0]\n",
    "    \n",
    "    sorted_test_index = sorted(test_index)\n",
    "    sorted_pred_y = [y for x,y in sorted(zip(test_index,pred_y))] \n",
    "    sorted_act_y = [y for x,y in sorted(zip(test_index,act_y))] \n",
    "\n",
    "    \n",
    "    for i,v in enumerate(sorted_act_y):\n",
    "        if v == 1.0:\n",
    "            index_stable = i\n",
    "            break\n",
    "    \n",
    "    sort = {k: v for k, v in sorted(feature_frequencies.items(), key=lambda item: item[1], reverse = True)}\n",
    "    label = sort.keys()\n",
    "    frequencies = list(sort.values())\n",
    "    index = np.arange(len(label))  \n",
    "    \n",
    "    plt.figure(figsize=(20,10), dpi=80)\n",
    "\n",
    "    ax1 = plt.subplot(211)\n",
    "    \n",
    "    title = f\"PPV: {PPV}\\n Number of Subjects Correctly Classified: {num_c}\\n Number of Progressor Subtypes: {num_P} \\n Number of Stable Subtypes: {num_S} \\n Classifier: {classifier} \\n Number of Features: {num_Features}\\n Class with High PPV:{subtype}\\n Stability: {stability}\\n Weighting: {weighting}\"\n",
    "    plt.title(title)\n",
    "    plt.xticks(index, label,rotation=50)\n",
    "    \n",
    "    for i in index:\n",
    "        if i < num_Features:\n",
    "            plt.bar(i, frequencies[i], color = 'red')\n",
    "        else:\n",
    "            plt.bar(i, frequencies[i], color = 'blue')\n",
    "        ax1.annotate(frequencies[i],\n",
    "\n",
    "                        (i, frequencies[i]),\n",
    "\n",
    "                         xytext=(0, 0), \n",
    "\n",
    "                         textcoords='offset points')\n",
    "\n",
    "    ax1.set_xlabel('Feature Index')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    ######################################################################################\n",
    "\n",
    "    ax2 = plt.subplot(212)\n",
    "    ax2.title.set_text('Confusion Matrix')\n",
    "    \n",
    "    for i,v in enumerate(sorted_pred_y):\n",
    "        if sorted_test_index[i] in indexes:\n",
    "            plt.plot(sorted_test_index[i], v, 'x', color='red')\n",
    "        else:\n",
    "            plt.plot(sorted_test_index[i], v, 'x', color='black')\n",
    "        \n",
    "    plt.axvline(x=250.5,color='r', linestyle='-')\n",
    "    plt.axhline(y=num_P-0.5, color='k', linestyle='-')\n",
    "    \n",
    "    # plt.axis([0, 302, 0, num_P+num_S])\n",
    "    plt.yticks(np.arange(0, num_P+num_S, 1.0))\n",
    "    ax2.set_xlabel('Instance indexes')\n",
    "    \n",
    "    plt.text(0.25, 0.06, \"Progressor Scans\", fontsize=16, transform=plt.gcf().transFigure)\n",
    "    plt.text(0.75, 0.06, \"Stables Scans\", fontsize=16, transform=plt.gcf().transFigure)\n",
    "\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    \n",
    "    name = 'analysis{}.png'.format(str(analysis))\n",
    "    file_path = path + name\n",
    "    \n",
    "    plt.savefig(file_path)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#     plt.show()\n",
    "#     return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Entry Point of the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_set = []\n",
    "num_P_column = np.array(good_results['num_P'])\n",
    "num_S_column = np.array(good_results['num_S'])\n",
    "classifier_column = np.array(good_results['classifier'])\n",
    "weighting_column = np.array(good_results['weighting'])\n",
    "\n",
    "for i in range(good_results.shape[0]):\n",
    "    param = [(num_P_column[i], num_S_column[i], classifier_column[i], weighting_column[i]), i]\n",
    "    print(param)\n",
    "    param_set.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(param_set))\n",
    "print(good_results.at[0,'precision_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_param_set = list(set([i[0] for i in param_set]))\n",
    "print(unique_param_set)\n",
    "print(len(unique_param_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_col = ['PPV', 'Subjects Correctly Classified', \n",
    "                 'Number of Progressor Subtypes', \n",
    "                 'Number of Stable Subtypes', \n",
    "                 'Number of Features', \n",
    "                 'Classifier',\n",
    "                 'Weighting', \n",
    "                 'Class with High PPV', \n",
    "                 'Stability of High PPV',\n",
    "                 'Number of features mutually selected', \n",
    "                 'Percentage of Mutual Features Selected across all folds', \n",
    "                 'Features selected with highest frequencies across all folds', \n",
    "                 'Frequencies of the features',\n",
    "                 'Indexes of Instances Correctly Classified'\n",
    "                ]\n",
    "\n",
    "result_df = pd.DataFrame(columns = result_df_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_param_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_results.at[param[1], 'precision_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_results.columns)\n",
    "dfs = []\n",
    "for u in unique_param_set:\n",
    "    print(u)\n",
    "    test_df = good_results[\n",
    "                                        (good_results['num_P'] == u[0]) & \n",
    "                                        (good_results['num_S'] == u[1]) & \n",
    "                                        (good_results['classifier'] == u[2]) & \n",
    "                                        (good_results['weighting'] == u[3])\n",
    "    ]\n",
    "    dfs.append(test_df)  \n",
    "#     print(test_df)\n",
    "demo_output = pd.concat(dfs, ignore_index=True)\n",
    "# demo_output = demo_output.drop(columns=['act_y', 'test_index','pred_y'])\n",
    "demo_output.to_csv(\"./X\"+dataset + \"_results/results/fold\" + fold+ \"/arranged_good.csv\")\n",
    "demo_output.to_pickle(\"./X\"+dataset + \"_results/results/fold\" + fold+ \"/arranged_good.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_set = []\n",
    "num_P_column = np.array(demo_output['num_P'])\n",
    "num_S_column = np.array(demo_output['num_S'])\n",
    "classifier_column = np.array(demo_output['classifier'])\n",
    "weighting_column = np.array(demo_output['weighting'])\n",
    "n_f = np.array(demo_output['num_Features'])\n",
    "\n",
    "for i in range(demo_output.shape[0]):\n",
    "    param = [(num_P_column[i], num_S_column[i], classifier_column[i], weighting_column[i]), i]\n",
    "    print(param)\n",
    "    print('num_Features', n_f[i])\n",
    "    param_set.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loop = 0\n",
    "for ii, unique_param in enumerate(unique_param_set):\n",
    "#     if ii != len(unique_param_set)-1:\n",
    "#         continue\n",
    "#     print(\"unique_param\", unique_param)\n",
    "    for c in range(3):\n",
    "        if unique_param[2] == 0:\n",
    "            classifier = \"SVM\"\n",
    "        elif unique_param[2] == 1:\n",
    "            classifier = \"RF\"\n",
    "        elif unique_param[2] == 2:\n",
    "            classifier = \"LR\"\n",
    "#     print(\"classifier \", classifier)\n",
    "    score_list = []\n",
    "    original_index = []\n",
    "    for param in param_set:\n",
    "        if param[0] == unique_param:\n",
    "#             print(\"param\", param)\n",
    "            keys = []\n",
    "            for k, v in demo_output.at[param[1], 'precision_score'].items():\n",
    "                keys.append(v)\n",
    "            score_list.append(keys)\n",
    "            original_index.append(param[1])\n",
    "            \n",
    "    score_arr = np.array(score_list)\n",
    "\n",
    "    print(score_arr.shape)\n",
    "#     print(\"score_arr\\n\", score_arr)\n",
    "#     print(\"original_index\", original_index)\n",
    "    \n",
    "    subtype_max_list = np.max(score_arr,axis=0)\n",
    "    \n",
    "#     print(\"subtype_max_list\", subtype_max_list)\n",
    "    \n",
    "    # [ expression for item in list if conditional ]\n",
    "    good_ppv_subtypes = [(i,v) for i,v in enumerate(subtype_max_list) if v > 0.8]\n",
    "    \n",
    "#     print(\"good_ppv_subtypes\", good_ppv_subtypes)\n",
    "    \n",
    "    for subtype,v in good_ppv_subtypes:\n",
    "#         print(\"subtype\", subtype)\n",
    "#         print(\"v\", v)\n",
    "        queue = [(index,score_arr[index][subtype]) for index in range(score_arr.shape[0]) if score_arr[index][subtype] > 0.8]\n",
    "#         print(\"queue\\n\", queue)\n",
    "        if len(queue) < 3:\n",
    "            continue\n",
    "        streaks,streak = [],[]\n",
    "        queue_cpy = queue.copy()\n",
    "        count = demo_output.at[original_index[0], 'num_Features']\n",
    "#         print(\"count \", count)\n",
    "        for j,ppv in queue:\n",
    "#             print((\"j: {}, ppv:{}\").format(j,ppv))\n",
    "            n_fea = demo_output.at[original_index[j], 'num_Features']\n",
    "#             print(\"num_features\", n_fea)\n",
    "            if count + 1 == n_fea:\n",
    "                streak.append((queue_cpy.pop(0),j))\n",
    "#                 print(\"streak\", streak)\n",
    "                count += 1\n",
    "            else:\n",
    "                if len(streak) >= 3:\n",
    "                    streaks.append(streak)\n",
    "                streak = []\n",
    "                streak.append((queue_cpy.pop(0),j))\n",
    "                count = demo_output.at[original_index[j], 'num_Features']\n",
    "                \n",
    "        if len(streak) != 0 and len(streak) > 3:\n",
    "            streaks.append(streak)\n",
    "        \n",
    "#         for s in streaks:\n",
    "#             print(s)\n",
    "        \n",
    "        final_streaks = []\n",
    "        \n",
    "        if len(streaks) == 0:\n",
    "            continue\n",
    "            \n",
    "        for stk in streaks:\n",
    "#             print(\"stk\", stk)\n",
    "#             print(\"stability\", len(stk))\n",
    "            max_index = np.argmax([i[0][1] for i in stk], axis=0)\n",
    "            max_ppv = stk[max_index][0][1]\n",
    "#             print(\"max_ppv\", max_ppv)\n",
    "            if max_ppv > 0.94:\n",
    "                final_streaks.append(stk)\n",
    "                \n",
    "        for fstk in final_streaks:\n",
    "#             print(\"fstk\", fstk)\n",
    "            stability = len(fstk)\n",
    "#             print(\"stability\", stability)\n",
    "            max_index = np.argmax([i[0][1] for i in fstk], axis=0)\n",
    "            max_ppv = fstk[max_index][0][1]\n",
    "#             print(\"max_ppv\", max_ppv)\n",
    "            indexes = [x[1] for i, x in enumerate(fstk) if x[0][1] == max_ppv]\n",
    "#             print(\"indexes\", indexes)\n",
    "            init_indexes = [original_index[i] for i in indexes]\n",
    "#             print(\"init_indexes\", init_indexes)\n",
    "            num_Features = [demo_output.at[i, 'num_Features'] for i in init_indexes]\n",
    "#             print(\"num_features\", num_Features)\n",
    "#             print(\"subtype\", subtype)\n",
    "            correctly_classified = [\n",
    "                        calculateCorrectlyClassifiedSubjects(\n",
    "                        demo_output.at[i, 'pred_y'], \n",
    "                        demo_output.at[i, 'act_y'],\n",
    "                        demo_output.at[i, 'test_index'],\n",
    "                        subtype,\n",
    "                        demo_output.at[i, 'num_P'],\n",
    "                        demo_output.at[i, 'num_S'])\n",
    "                for i in init_indexes\n",
    "            ]\n",
    "                \n",
    "#             print(\"correctly_classified\", correctly_classified)\n",
    "\n",
    "            mfs = [featureSelectionValidation(\n",
    "                                                                                        df_results_of_each_fold, \n",
    "                                                                                        unique_param[0],\n",
    "                                                                                        unique_param[1],\n",
    "                                                                                        unique_param[2],\n",
    "                                                                                        unique_param[3],\n",
    "                                                                                        j \n",
    "                                                                                    )\n",
    "                                                           for j in num_Features\n",
    "                                                          ]\n",
    "            \n",
    "#             print(\"featureSelectionValidation\", mfs)\n",
    "            \n",
    "            percentage_mf = [i[0] for i in mfs]\n",
    "            num_mf = [i[2] for i in mfs]\n",
    "            \n",
    "#             print(\"percentage_mf\", percentage_mf)\n",
    "#             print(\"num_mf\", num_mf)\n",
    "            \n",
    "            best_index = np.argmax([x for x,v in correctly_classified], axis=0)\n",
    "            max_subject = correctly_classified[best_index][0]\n",
    "            \n",
    "#             print(\"best_index: \", best_index)\n",
    "#             print(\"max_subject: \", max_subject)   \n",
    "            \n",
    "            best_indexes = [i for i, x in enumerate([i for (i,x) in correctly_classified]) if x == max_subject]\n",
    "#             print(\"best_indexes\", best_indexes)\n",
    "            if max_subject > 1:\n",
    "#                 print(\"max_subject\", max_subject)\n",
    "                if len(best_indexes) > 1:\n",
    "                    # print(\"pct mfs\", [percentage_mf[i] for i in best_indexes])\n",
    "#                     best_fss = [(percentage_mf[i],i) for i in best_indexes]\n",
    "#                     best_fs_i = np.argmax([val[0] for val in best_fss], axis=0)\n",
    "#                     best_fs_index = best_fss[best_fs_i][1]\n",
    "\n",
    "                    nfeats = [num_Features[i] for i in best_indexes]\n",
    "                    nfeas_mid = statistics.mean(nfeats)   \n",
    "                    bi = np.argmin([abs(d-nfeas_mid) for d in nfeats], axis=0)\n",
    "                \n",
    "                    best_fs_index = best_indexes[bi]\n",
    "                    \n",
    "                    \n",
    "#                     print(\"best_fs_index\", best_fs_index)\n",
    "                    # print(\"correctly_classified\", correctly_classified[best_fs_index])\n",
    "                else:\n",
    "                    best_fs_index = best_indexes[0]\n",
    "                    \n",
    "                dic, features_list = computeFeatureFrequencies(df_results_of_each_fold, \n",
    "                                                                     unique_param[0], \n",
    "                                                                     unique_param[1], \n",
    "                                                                     unique_param[2], \n",
    "                                                                     num_Features[best_fs_index],\n",
    "                                                                     unique_param[3]\n",
    "                                                                )\n",
    "                \n",
    "\n",
    "                sorted_features_frequencies = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)}\n",
    "                features_frequencies = list(sorted_features_frequencies.values())[:num_Features[best_fs_index]]\n",
    "                features_selected_list = list(sorted_features_frequencies.keys())[:num_Features[best_fs_index]]\n",
    "                \n",
    "                if featuresThreshold(features_frequencies, features_selected_list, 0.5) == False:\n",
    "                    continue\n",
    "                \n",
    "\n",
    "#                 print('Number of Features', num_Features[best_fs_index])\n",
    "#                 print('features_frequencies', features_frequencies)\n",
    "#                 print('features_selected_list', features_selected_list)\n",
    "#                 print('len features_selected_list', len(features_selected_list))\n",
    "#                 print('len features_frequencies', len(features_frequencies))\n",
    "                \n",
    "                row = {'PPV': max_ppv, \n",
    "                    'Subjects Correctly Classified': correctly_classified[best_fs_index][0], \n",
    "                    'Number of Progressor Subtypes': unique_param[0], \n",
    "                    'Number of Stable Subtypes': unique_param[1], \n",
    "                    'Number of Features': num_Features[best_fs_index], \n",
    "                    'Classifier': classifier, \n",
    "                    'Weighting': unique_param[3],\n",
    "                    'Class with High PPV': subtype,\n",
    "                    'Stability of High PPV': stability,\n",
    "                    'Number of features mutually selected': num_mf[best_fs_index],\n",
    "                    'Percentage of Mutual Features Selected across all folds':percentage_mf[best_fs_index],\n",
    "                    'Features selected with highest frequencies across all folds': features_selected_list, \n",
    "                    'Frequencies of the features':features_frequencies,\n",
    "                    'Indexes of Instances Correctly Classified': correctly_classified[best_fs_index][1]\n",
    "                }\n",
    "                result_df = result_df.append(row, ignore_index=True)\n",
    "    loop = loop +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./X\"+dataset+\"_results/results/fold\" + fold + \"/filtered_good_results_fold\" + fold + \".csv\")\n",
    "result_df.to_pickle(\"./X\"+dataset+\"_results/results/fold\" + fold  + \"/filtered_good_results_fold\" + fold + \".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_results_filtered = pd.read_pickle(\"./X\"+dataset+\"_results/results/fold\" + fold + \"/filtered_good_results_fold\" + fold + \".pkl\")\n",
    "path = './X'+dataset+'_results/results/fold' + fold + '/inner_cv_analysis/'\n",
    "\n",
    "for index, row in filtered_results_filtered.iterrows():\n",
    "    ppv = row['PPV']\n",
    "    subject_correctly_classified = row['Subjects Correctly Classified']\n",
    "    num_c = row['Subjects Correctly Classified']\n",
    "    num_P = row['Number of Progressor Subtypes']\n",
    "    num_S = row['Number of Stable Subtypes']\n",
    "    num_Features = row['Number of Features']\n",
    "    convert = lambda x: 0 if (x==\"SVM\") else 1 if (x==\"RF\") else 2\n",
    "    classifier = convert(row['Classifier'])\n",
    "    index_of_correct_instances = row['Indexes of Instances Correctly Classified']\n",
    "    stability = row['Stability of High PPV']\n",
    "    subtype = row['Class with High PPV']\n",
    "    weighting = row['Weighting']\n",
    "    \n",
    "    dic,_ = computeFeatureFrequencies(df_results_of_each_fold, num_P, num_S, classifier, num_Features, weighting)\n",
    "    \n",
    "    plotFigures(df_results_of_each_param, \n",
    "                    dic, \n",
    "                    ppv, \n",
    "                    num_c, \n",
    "                    num_P, \n",
    "                    num_S, \n",
    "                    classifier, \n",
    "                    num_Features, \n",
    "                    subtype, \n",
    "                    stability, \n",
    "                    weighting, \n",
    "                    index_of_correct_instances, \n",
    "                    index, \n",
    "                    path \n",
    "               )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
